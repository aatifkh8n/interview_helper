// const WebSocket = require('ws');
// const fs = require('fs');
// const { SpeechClient } = require('@google-cloud/speech');
// const path = require('path');
// const ffmpeg = require('fluent-ffmpeg');
// const ffmpegPath = require('ffmpeg-static');

// // Set the path for FFmpeg binary (if using ffmpeg-static)
// ffmpeg.setFfmpegPath(ffmpegPath);

// // Initialize Google Cloud Speech API client
// const client = new SpeechClient();

// async function convertWebmToWav(audio) {
//     console.log('FFmpeg path:', ffmpegPath);
//     return new Promise((resolve, reject) => {
//         const inputFile = audio; // Path to your input .webm file
//         const outputFile = 'output.wav'; // Path to save the output .wav file

//         // reject(new Error(ffmpeg));

//         ffmpeg(inputFile)
//             .output(outputFile)
//             .audioCodec('pcm_s16le')  // WAV audio codec
//             .audioChannels(1)         // Mono audio (you can change this to 2 for stereo)
//             .audioFrequency(16000)    // Set sample rate to 16kHz (standard for transcription)
//             .on('end', () => {
//                 console.log('Conversion complete!');
//                 resolve(outputFile); // Return the path to the .wav file
//             })
//             .on('error', (err) => {
//                 console.error('Error during conversion:', err);
//                 reject(new Error(`Failed to convert WebM to WAV ERROR: ${err}`));
//             })
//             .run();
//     });
// }

// // WebSocket server on port 8080
// // const wss = new WebSocket.Server({ port: 8080 }, () => {
// //     console.log('WebSocket server started on ws://localhost:8080');
// // });

// // wss.on('connection', (ws) => {
// //     console.log('Client connected.');

// //     ws.on('message', async (data) => {
// //         try {
// //             // Save received audio data to a file
// //             const audioPath = path.join(__dirname, 'received_audio.wav');
// //             fs.writeFileSync(audioPath, data);
// //             console.log('Audio data saved to "received_audio.wav".');

// //             // Transcribe the audio using Google Cloud Speech API
// //             const transcription = await transcribeAudioViaPath(audioPath);

// //             // Send the transcription back to the client
// //             ws.send(transcription);
// //             console.log('Sent transcription to client.');

// //             // Clean up the audio file after processing
// //             fs.unlinkSync(audioPath);
// //             console.log('Audio file removed from the server.');
// //         } catch (error) {
// //             console.error('Error processing audio:', error);
// //             ws.send('An error occurred during transcription.');
// //         }
// //     });

// //     ws.on('close', () => {
// //         console.log('Client disconnected.');
// //     });
// // });

// export async function transcribeAudioViaPath(audioPath) {
//     const audioBytes = fs.readFileSync(audioPath).toString('base64');

//     const audio = {
//         content: audioBytes,
//     };

//     const res = await transcribeAudio(audio);
//     return res;
// }

// // Function to transcribe audio file using Google Cloud Speech API
// export async function transcribeAudio(audio) {

//     const wavAudio = await convertWebmToWav(audio);

//     const config = {
//         encoding: 'LINEAR16',
//         sampleRateHertz: 16000,
//         languageCode: 'en-US',
//     };

//     const request = {
//         audio: wavAudio,
//         config,
//     };

//     try {
//         const [response] = client.recognize(request);
//         const transcription = response.results
//             .map(result => result.alternatives[0].transcript)
//             .join('\n');
//         return transcription;
//     } catch (error) {
//         console.error('Error transcribing audio:', error);
//         throw new Error('Failed to transcribe audio');
//     }
// }


// async function convertWebmToWav(audio) {
//     return new Promise((resolve, reject) => {
//         const inputFile = audio; // Path to your input .webm file
//         const outputFile = 'output.wav'; // Path to save the output .wav file

//         webmToWav(inputFile, outputFile)
//             .then(() => {
//                 console.log('Conversion successful!');
//                 resolve(outputFile); // Return the path to the .wav file
//             })
//             .catch(err => {
//                 console.error('Error during conversion:', err);
//                 reject(new Error(`Failed to convert WebM to WAV ERROR: ${err}`));
//             });

//     });
// }

// WebSocket server on port 8080
// const wss = new WebSocket.Server({ port: 8080 }, () => {
//     console.log('WebSocket server started on ws://localhost:8080');
// });

// wss.on('connection', (ws) => {
//     console.log('Client connected.');

//     ws.on('message', async (data) => {
//         try {
//             // Save received audio data to a file
//             const audioPath = path.join(__dirname, 'received_audio.wav');
//             fs.writeFileSync(audioPath, data);
//             console.log('Audio data saved to "received_audio.wav".');

//             // Transcribe the audio using Google Cloud Speech API
//             const transcription = await transcribeAudioViaPath(audioPath);

//             // Send the transcription back to the client
//             ws.send(transcription);
//             console.log('Sent transcription to client.');

//             // Clean up the audio file after processing
//             fs.unlinkSync(audioPath);
//             console.log('Audio file removed from the server.');
//         } catch (error) {
//             console.error('Error processing audio:', error);
//             ws.send('An error occurred during transcription.');
//         }
//     });

//     ws.on('close', () => {
//         console.log('Client disconnected.');
//     });
// });